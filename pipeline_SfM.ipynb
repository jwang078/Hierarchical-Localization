{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from hloc import (\n",
    "    extract_features,\n",
    "    match_features,\n",
    "    reconstruction,\n",
    "    visualization,\n",
    "    pairs_from_retrieval,\n",
    ")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In this notebook, we will run SfM reconstruction from scratch on a set of images. We choose the [South-Building dataset](https://openaccess.thecvf.com/content_cvpr_2013/html/Hane_Joint_3D_Scene_2013_CVPR_paper.html) - we will download it later. First, we define some paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = Path(\"/home/jennyw2/data/small_engine_on_table_2/images_500_highres\")\n",
    "# outputs = Path(\"outputs/small_engine_on_table_2_500imgs_highres_10match\")\n",
    "\n",
    "# video_path is either a path or None\n",
    "# video_path = Path(\"/home/jennyw2/data/container_scan_videos_20250903/20250903_143802000_iOS/20250903_143802000_iOS.MOV\")\n",
    "# images = Path(\"/home/jennyw2/data/container_scan_videos_20250903/20250903_143802000_iOS/images_500\")\n",
    "# num_matched = 20\n",
    "\n",
    "# Doing the things before training splat\n",
    "video_path = Path(\"/home/jennyw2/data/container_scan_videos_20250903/20250903_143802000_iOS/20250903_143802000_iOS.MOV\")\n",
    "images = Path(\"/home/jennyw2/data/container_scan_videos_20250903/20250903_143802000_iOS/images_500\")\n",
    "num_matched = 40\n",
    "\n",
    "# The thing training gaussian splat\n",
    "# video_path = Path(\"/home/jennyw2/data/container_scan_videos_20250903/20250903_143627000_iOS/20250903_143627000_iOS.MOV\")\n",
    "# images = Path(\"/home/jennyw2/data/container_scan_videos_20250903/20250903_143627000_iOS/images_500\")\n",
    "# num_matched = 20\n",
    "\n",
    "image_height = 540 # only used if video_path is converted in this notebook\n",
    "\n",
    "# Everything after the data/ folder prefix\n",
    "experiment_name = \"_\".join(images.parts[4:]) + f\"_{num_matched}match\" + f\"_{image_height}height\"\n",
    "outputs = Path(\"/home/jennyw2/code/Hierarchical-Localization/outputs/\") / experiment_name\n",
    "\n",
    "sfm_pairs = outputs / \"pairs-netvlad.txt\"\n",
    "\n",
    "# sfm_dir = outputs / \"sfm_superpoint+superglue\"\n",
    "# retrieval_conf = extract_features.confs[\"netvlad\"]\n",
    "# feature_conf = extract_features.confs[\"superpoint_aachen\"]\n",
    "# matcher_conf = match_features.confs[\"superglue\"]\n",
    "\n",
    "sfm_dir = outputs / \"sfm_disk_disk+lightglue\" / \"distorted\"\n",
    "retrieval_conf = extract_features.confs[\"netvlad\"]\n",
    "feature_conf = extract_features.confs[\"disk\"]\n",
    "matcher_conf = match_features.confs[\"disk+lightglue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jennyw2/data/container_scan_videos_20250903/20250903_143802000_iOS/20250903_143802000_iOS.MOV\n",
      "/home/jennyw2/data/container_scan_videos_20250903/20250903_143802000_iOS/images_500\n",
      "/home/jennyw2/code/Hierarchical-Localization/outputs/container_scan_videos_20250903_20250903_143802000_iOS_images_500_40match_540height\n"
     ]
    }
   ],
   "source": [
    "print(video_path)\n",
    "print(images)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/jennyw2/data/container_scan_videos_20250903/20250903_143802000_iOS/images_500’: File exists\n",
      "frame= 1311 fps=145 q=1.0 Lsize=N/A time=00:00:43.70 bitrate=N/A speed=4.82x    \n",
      "Found a total of 1311 images to work on.\n",
      "Calculating image sharpness...\n",
      "100%|███████████████████████████████████████| 1311/1311 [00:25<00:00, 51.73it/s]\n",
      "Requested 500 out of 1311 images (38.1%, 1 in 2.6).\n",
      "Selecting 500 images across 125 groups, with total ~10.5 images per group and selecting ~4.0 images per group (scalar 3).\n",
      "Group layout:\n",
      " [▁█▁▅█▁█▅▁█▁▅█▁█▅▁█▁▅█▁█▅▁█▁▅█▁█▅▁█▁▅█▁█▅▁█▁▅█▁█▅▁█▁▅█▁█▅▁█▁▅█▁█▅▁█▁▅█▁█▅▁█▁▅█▁█▅▁█▁▅█▁█▅▁█▁▅█▁█▅▁█▁▅]\n",
      "\n",
      "Distribution of to-be-deleted images:\n",
      " [▅▃▆▅▅▃▆▅▅▅▅▅▅▅▅▆▃▆▅▅▃▆▅▆▃▅▆▅▃▅▃▆▅▅▃▆▅▆▅▅▃▅▆▃▆▅▅▆▃▅▃▇▂▆▅▆▃▆▅▃▃▇▅▅▃▅▅▅▅▅▆▆▃▅▅▂▅▆▆▆▃▃▆▆▆▃▅▅▁▇▅▆▃▃█▃▂█▃▅]\n",
      "\n",
      "Distribution of image quality:\n",
      " [▆▇▆▅▆▆▆▆▆▅▆▄▃▃▃▃▃▃▃▃▃▃▃▃▄▅▅▇▇██▇▇▇▇▆▅▄▅▅▅▆▅▆▅▅▅▄▄▃▃▃▄▃▃▃▃▄▅▅▄▄▅▆▅▅▅▅▄▃▄▆███▆▂▁▂▅▆▃▁▂▄▅▆▇▇▆▄▄▅▃▄▅▅▃▂▃]\n",
      "\n",
      "Retained 500 sharpest images.\n"
     ]
    }
   ],
   "source": [
    "if video_path is not None:\n",
    "    ! mkdir $images\n",
    "    ! conda run --no-capture-output -n nerfstudio python ~/code/nerf_dataset_preprocessing_helper/01_filter_raw_data.py --input_path $video_path --output_path $images --target_count 500 --scalar 3 -y\n",
    "else:\n",
    "    print(\"Skipping video to image conversion because video_path is not provided\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "resized_image_dir = images / \"resized_images\"\n",
    "os.makedirs(resized_image_dir, exist_ok=True)\n",
    "\n",
    "for fname in os.listdir(images):\n",
    "    if fname.endswith(\".jpg\"):\n",
    "        in_path = os.path.join(images, fname)\n",
    "        out_path = os.path.join(resized_image_dir, f\"{os.path.splitext(fname)[0]}.jpg\")\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-y\", \"-i\", in_path,\n",
    "            \"-vf\", f\"scale=-1:{image_height}\",\n",
    "            out_path\n",
    "        ]\n",
    "        subprocess.run(cmd, check=True)\n",
    "\n",
    "# Hide the output of this cell\n",
    "clear_output(wait=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for f in images.glob(\"*.jpg\"):\n",
    "    f.unlink()  # delete unresized images\n",
    "for f in resized_image_dir.glob(\"*.jpg\"): \n",
    "    shutil.move(str(f), images / f.name) # move resized images to the original locations\n",
    "shutil.rmtree(resized_image_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "The dataset is simply a set of images. The intrinsic parameters will be extracted from the EXIF data and refined with SfM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not images.exists():\n",
    "#     !wget https://cvg-data.inf.ethz.ch/local-feature-evaluation-schoenberger2017/South-Building.zip -P datasets/\n",
    "#     !unzip -q datasets/South-Building.zip -d datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find image pairs via image retrieval\n",
    "We extract global descriptors with NetVLAD and find for each image the most similar ones. For smaller dataset we can instead use exhaustive matching via `hloc/pairs_from_exhaustive.py`, which would find $\\frac{n(n-1)}{2}$ images pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025/09/18 11:05:12 hloc INFO] Extracting local features with configuration:\n",
      "{'model': {'name': 'netvlad'},\n",
      " 'output': 'global-feats-netvlad',\n",
      " 'preprocessing': {'resize_max': 1024}}\n",
      "[2025/09/18 11:05:12 hloc INFO] Found 500 images in root /home/jennyw2/data/container_scan_videos_20250903/20250903_143802000_iOS/images_500.\n",
      "100%|█████████████████████████████████████████| 500/500 [02:47<00:00,  2.99it/s]\n",
      "[2025/09/18 11:08:04 hloc INFO] Finished exporting features.\n",
      "[2025/09/18 11:08:04 hloc INFO] Extracting image pairs from a retrieval database.\n",
      "[2025/09/18 11:08:05 hloc INFO] Found 20000 pairs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_path = extract_features.main(retrieval_conf, images, outputs)\n",
    "pairs_from_retrieval.main(retrieval_path, sfm_pairs, num_matched=num_matched) #5)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and match local features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025/09/18 11:08:05 hloc INFO] Extracting local features with configuration:\n",
      "{'model': {'max_keypoints': 5000, 'name': 'disk'},\n",
      " 'output': 'feats-disk',\n",
      " 'preprocessing': {'grayscale': False, 'resize_max': 1600}}\n",
      "[2025/09/18 11:08:05 hloc INFO] Found 500 images in root /home/jennyw2/data/container_scan_videos_20250903/20250903_143802000_iOS/images_500.\n",
      "100%|█████████████████████████████████████████| 500/500 [01:55<00:00,  4.34it/s]\n",
      "[2025/09/18 11:10:00 hloc INFO] Finished exporting features.\n",
      "[2025/09/18 11:10:00 hloc INFO] Matching local features with configuration:\n",
      "{'model': {'features': 'disk', 'name': 'lightglue'},\n",
      " 'output': 'matches-disk-lightglue'}\n",
      "100%|███████████████████████████████████| 11537/11537 [6:12:36<00:00,  1.94s/it]\n",
      "[2025/09/18 17:22:37 hloc INFO] Finished exporting matches.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_path = extract_features.main(feature_conf, images, outputs)\n",
    "match_path = match_features.main(\n",
    "    matcher_conf, sfm_pairs, feature_conf[\"output\"], outputs\n",
    ")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jennyw2/code/Hierarchical-Localization/outputs/container_scan_videos_20250903_20250903_143802000_iOS_images_500_40match_540height/feats-disk_matches-disk-lightglue_pairs-netvlad.h5')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D reconstruction\n",
    "Run COLMAP on the features and matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025/09/18 17:22:37 hloc INFO] Writing COLMAP logs to /home/jennyw2/code/Hierarchical-Localization/outputs/container_scan_videos_20250903_20250903_143802000_iOS_images_500_40match_540height/sfm_disk_disk+lightglue/distorted/colmap.LOG.*\n",
      "[2025/09/18 17:22:37 hloc INFO] Creating an empty database...\n",
      "[2025/09/18 17:22:37 hloc INFO] Importing images into the database...\n",
      "[2025/09/18 17:22:38 hloc INFO] Importing features into the database...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1510.65it/s]\n",
      "[2025/09/18 17:22:39 hloc INFO] Importing matches into the database...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:10<00:00, 1984.27it/s]\n",
      "[2025/09/18 17:22:50 hloc INFO] Performing geometric verification of the matches...\n",
      "[2025/09/18 17:23:31 hloc INFO] Running 3D reconstruction...\n",
      "Reconstruction 0:   1%|█▊                                                                                                                                   | 7/500 [00:25<29:51,  3.63s/images, registered]\n",
      "Reconstruction 1:   2%|██▍                                                                                                                                  | 9/500 [00:12<20:53,  2.55s/images, registered]"
     ]
    }
   ],
   "source": [
    "model = reconstruction.main(sfm_dir, images, sfm_pairs, feature_path, match_path)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes, the above bugs out and doesn't save the best model into the main folder. Save the optimal model\n",
    "\n",
    "# First, move the model it copied over into another folder to save it\n",
    "maybe_wrong_saved_model_dir = sfm_dir / \"picked_model\"\n",
    "os.makedirs(maybe_wrong_saved_model_dir, exist_ok=True)\n",
    "\n",
    "# for maybe_wrong_model_file in os.listdir(sfm_dir):\n",
    "    if os.path.isfile(os.path.join(sfm_dir, maybe_wrong_model_file)):\n",
    "        print(maybe_wrong_model_file)\n",
    "        os.rename(os.path.join(sfm_dir, maybe_wrong_model_file), os.path.join(maybe_wrong_saved_model_dir, maybe_wrong_model_file))\n",
    "\n",
    "# Save the model still in memory\n",
    "model.write(sfm_dir)\n",
    "\n",
    "# TODO deallocate the model\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "We visualize some of the registered images, and color their keypoint by visibility, track length, or triangulated depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(model, images, color_by=\"visibility\", n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(model, images, color_by=\"track_length\", n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(model, images, color_by=\"depth\", n=5)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset for gaussian splat optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! rm -r $sfm_dir/../undistorted && echo Overwriting previous undistorted/ folder...\n",
    "! colmap image_undistorter --image_path $images --input_path $sfm_dir --output_path $sfm_dir/../undistorted\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir $sfm_dir/../undistorted/sparse/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv $sfm_dir/../undistorted/sparse/*.* $sfm_dir/../undistorted/sparse/0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train gaussian splat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda deactivate; conda activate gaussian_splatting; cd /home/jennyw2/code/gaussian-splatting-repo/gaussian_splatting\n",
      "python train.py -s /home/jennyw2/code/Hierarchical-Localization/outputs/container_scan_videos_20250903_20250903_143627000_iOS_images_500_20match_540height/sfm_disk_disk+lightglue/distorted/../undistorted --eval --model_path output/container_scan_videos_20250903_20250903_143627000_iOS_images_500_20match_540height\n"
     ]
    }
   ],
   "source": [
    "print(f\"conda deactivate; conda activate gaussian_splatting; cd /home/jennyw2/code/gaussian-splatting-repo/gaussian_splatting\")\n",
    "print(f\"python train.py -s {sfm_dir}/../undistorted --eval --model_path output/{experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing output/container_scan_videos_20250903_20250903_143627000_iOS_images_500_20match_540height\n",
      "Output folder: output/container_scan_videos_20250903_20250903_143627000_iOS_images_500_20match_540height [18/09 10:47:14]\n",
      "Tensorboard not available: not logging progress [18/09 10:47:14]\n",
      "------------LLFF HOLD------------- [18/09 10:47:15]\n",
      "Reading camera 500/500 [18/09 10:47:15]\n",
      "Converting point3d.bin to .ply, will happen only the first time you open the scene. [18/09 10:47:15]\n",
      "Loading Training Cameras [18/09 10:47:15]\n",
      "Loading Test Cameras [18/09 10:47:20]\n",
      "Number of points at initialisation :  116494 [18/09 10:47:21]\n",
      "Training progress:  23%|▏| 7000/30000 [14:38<1:13:13,  5.23it/s, Loss=0.0738051,\n",
      "[ITER 7000] Evaluating test: L1 0.05474777930667476 PSNR 22.771764906625897 [18/09 11:02:03]\n",
      "\n",
      "[ITER 7000] Evaluating train: L1 0.05195741280913353 PSNR 22.685344314575197 [18/09 11:02:04]\n",
      "\n",
      "[ITER 7000] Saving Gaussians [18/09 11:02:04]\n",
      "Training progress:  25%|▎| 7600/30000 [16:45<1:15:28,  4.95it/s, Loss=0.0656465,Traceback (most recent call last):\n",
      "  File \"/home/jennyw2/code/gaussian-splatting-repo/gaussian_splatting/train.py\", line 286, in <module>\n",
      "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
      "  File \"/home/jennyw2/code/gaussian-splatting-repo/gaussian_splatting/train.py\", line 175, in training\n",
      "    gaussians.densify_and_prune(opt.densify_grad_threshold, 0.005, scene.cameras_extent, size_threshold, radii)\n",
      "  File \"/home/jennyw2/code/gaussian-splatting-repo/gaussian_splatting/scene/gaussian_model.py\", line 458, in densify_and_prune\n",
      "    self.densify_and_split(grads, max_grad, extent)\n",
      "  File \"/home/jennyw2/code/gaussian-splatting-repo/gaussian_splatting/scene/gaussian_model.py\", line 430, in densify_and_split\n",
      "    self.densification_postfix(new_xyz, new_features_dc, new_features_rest, new_opacity, new_scaling, new_rotation, new_tmp_radii)\n",
      "  File \"/home/jennyw2/code/gaussian-splatting-repo/gaussian_splatting/scene/gaussian_model.py\", line 396, in densification_postfix\n",
      "    optimizable_tensors = self.cat_tensors_to_optimizer(d)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jennyw2/code/gaussian-splatting-repo/gaussian_splatting/scene/gaussian_model.py\", line 378, in cat_tensors_to_optimizer\n",
      "    group[\"params\"][0] = nn.Parameter(torch.cat((group[\"params\"][0], extension_tensor), dim=0).requires_grad_(True))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 410.00 MiB. GPU 0 has a total capacity of 10.90 GiB of which 420.31 MiB is free. Process 48628 has 1.78 GiB memory in use. Including non-PyTorch memory, this process has 8.40 GiB memory in use. Of the allocated memory 6.71 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Training progress:  25%|▎| 7600/30000 [16:45<49:23,  7.56it/s, Loss=0.0656465, D\n",
      "ERROR conda.cli.main_run:execute(125): `conda run python train.py -s /home/jennyw2/code/Hierarchical-Localization/outputs/container_scan_videos_20250903_20250903_143627000_iOS_images_500_20match_540height/sfm_disk_disk+lightglue/distorted/../undistorted --eval --model_path output/container_scan_videos_20250903_20250903_143627000_iOS_images_500_20match_540height` failed. (See above for error)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! cd /home/jennyw2/code/gaussian-splatting-repo/gaussian_splatting; conda run --no-capture-output -n gaussian_splatting python train.py -s $sfm_dir/../undistorted --eval --model_path output/$experiment_name\n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
